{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Welcome to the University of Iowa HPC Documentation Site","text":""},{"location":"#introduction","title":"Introduction","text":"<p>The University of Iowa supports researchers and their external collaborators by providing access to advanced supercomputing resources. Information Technology Services (ITS) operates several key systems, including the Argon High Performance Computing (HPC) cluster, the Interactive Data Analytic Service (IDAS), and a variety of Storage Services.</p> <p>In addition to the comprehensive Argon wiki pages, this site is designed to help users effectively utilize HPC resources for computational research projects. If you have any questions or feedback about the content of this site, please contact us. </p>"},{"location":"#news","title":"News","text":"<ul> <li> <p> November 2025 Argon Maintenance</p> <ul> <li>The Fall 2025 maintenance will be from 8:00 AM on November 19th until 8:00 AM on November 20th</li> </ul> </li> <li> <p> Argon OS and Scheduler Update</p> <ul> <li>Cent OS7 to Rocky</li> <li>SGE to SLURM</li> </ul> </li> <li> <p> Fall Semester 2025 Workshops</p> <ul> <li>Basic Linux </li> <li>Intro HPC</li> </ul> </li> <li> <p> Storage Modernization</p> <ul> <li>Large Scale Storage from zfs to Ceph</li> </ul> </li> </ul>"},{"location":"#featured-links-for-research-services","title":"Featured links for Research Services","text":"<p> Argon: High-Perfmance Computing (HPC) </p> <p> Accounts on the Argon HPC system are available at no cost to UI faculty, staff, and students who conduct research. Faculty members may sponsor access for research collaborators who are not part of the UI community and may purchase dedicated compute node capacity for their groups.</p> <p> Interactive Data Analytics Services (IDAS) </p> <p> A high performance computing (HPC) resource that supports large-scale and collaborative data analytics workflows involving RStudio, Jupyter Notebooks, and Jupyter Lab </p> <p> Storage Services </p> <p> Store and share research data files </p> <p> Research Remote Desktop Service (RRDS) </p> <p> A Windows virtual desktop environment through which users can remotely access research data and pre-installed analysis software. </p> <p> Comprehensive Argon Manual at Wiki </p> <p> Comprehensive information about how to utilize Argon cluster</p>"},{"location":"#acknowledgements","title":"Acknowledgements","text":"<p>The Argon HPC cluster at the University of Iowa is a collaboration and as such there are different acknowledgements that may be appropriate for your citation. See our guidelines for more details.</p>"},{"location":"blog/","title":"Blog","text":""},{"location":"get_started/access/","title":"Accessing the HPC System","text":"<p>The standard method for accessing Argon is via SSH (Secure Shell). You\u2019ll need an SSH client installed on your workstation:</p> <ul> <li>Linux/macOS: SSH is built-in. Open a terminal and initiate a session.</li> <li>Windows: Install an SSH client. The recommended option is SecureCRT, which is licensed by the University of Iowa.</li> </ul>"},{"location":"get_started/access/#connection-instructions","title":"Connection Instructions","text":""},{"location":"get_started/access/#on-campus-or-connected-via-vpn","title":"On Campus or Connected via VPN","text":"<pre><code>user@local ~&gt; ssh HawkID@argon.hpc.uiowa.edu\n</code></pre>"},{"location":"get_started/access/#off-campus-without-vpn","title":"Off Campus Without VPN","text":"<p>To enhance security, Argon uses an alternate SSH port when accessed from outside the campus network without VPN:</p> <pre><code>user@local ~&gt; ssh -p 40 HawkID@argon.hpc.uiowa.edu\n</code></pre> <p>Info</p> <p>For Windows users, enter the appropriate values in your SSH client\u2019s configuration fields. When prompted, enter your HawkID password. If successful, you\u2019ll be logged into one of Argon\u2019s login nodes.</p>"},{"location":"get_started/access/#login-node-behavior","title":"Login Node Behavior","text":"<p>Argon uses multiple login nodes, and SSH connections are distributed in a round-robin fashion. While you generally don\u2019t need to worry about which node you're connected to, be aware that different sessions may land on different nodes.</p> <p>Each login node has both an internal name (visible in your shell) and an external alias. This mapping may be useful if you need to reconnect to the same node:</p> Internal Name External Name (Alias) argon-itf-login-3.hpc argon-itf-login-3.hpc.uiowa.edu (argon-login-3.hpc.uiowa.edu) argon-itf-login-4.hpc argon-itf-login-4.hpc.uiowa.edu (argon-login-4.hpc.uiowa.edu) argon-login-5.hpc argon-login-5.hpc.uiowa.edu argon-login-6.hpc argon-login-6.hpc.uiowa.edu"},{"location":"get_started/overview/","title":"Getting Started with HPC","text":""},{"location":"get_started/overview/#what-is-an-hpc","title":"What is an HPC?","text":"<p>At its core, a High Performance Computing (HPC) cluster is a group of uniformly configured compute nodes that work together\u2014typically connected via high-bandwidth, low-latency networks\u2014to solve large-scale computational problems. These problems often require more memory or processing power than a typical workstation or single server can provide.</p> <p>When clustered, these nodes function as a unified system, enabling researchers to tackle complex tasks much more efficiently.</p> <p>An HPC cluster typically includes:</p> <ul> <li>Compute nodes: Ranging from a few to thousands, these perform the actual computations.</li> <li>Login or staging nodes: Used for accessing the system and preparing jobs.</li> <li>Head nodes: Manage job scheduling, resource allocation, and data coordination.</li> </ul>"},{"location":"get_started/overview/#what-is-a-scheduler","title":"What is a Scheduler?","text":"<p>A scheduler is a  software tool that manages and fairly distributes cluster resources among users. It works in tandem with a queuing system, which organizes jobs based on available resources or user access.</p> <p>Schedulers allow users to select:</p> <ul> <li>Parallel environments (PEs): For jobs requiring inter-node communication.</li> <li>Special resources: Such as GPUs, co-processors, or extra memory.</li> </ul> <p>Schedulers monitor job submissions and determine which jobs can run based on current resource availability. They may also prioritize jobs from users who use the system less frequently, ensuring equitable access and preventing resource monopolization.</p>"},{"location":"get_started/overview/#roadmap-for-utilizing-hpc-cluster-from-scratch","title":"Roadmap for utilizing HPC cluster from scratch","text":"<ol> <li> <p>Learn Basic Linux     Our cluster runs CentOS Linux. To use it effectively, you'll need basic command-line skills\u2014like navigating directories and editing files.</p> <ul> <li>Recommended resource: The Linux Command Line (free PDF)</li> <li>Quick reference: Linux Cheat Sheet</li> </ul> </li> <li> <p>Map Your Work to the Cluster</p> <p>If your project:</p> <ul> <li>Requires more memory than a desktop,</li> <li>Needs fast turnaround,</li> <li>Benefits from scheduled execution,</li> </ul> <p>...then HPC may be a good fit.</p> <p>Ask yourself:</p> <ul> <li>Does your code run on Linux?</li> <li>Can it be executed in batch mode?</li> <li>Is it a parallel (HPC) or serial (HTC) job?</li> </ul> </li> <li> <p>Consider Compilation Needs</p> <p>If you're migrating code from another system, you may need to recompile it\u2014especially if it uses MPI. See our notes on compiling software</p> </li> <li> <p>Check Software Availability</p> <p>Browse our Installed Software List. If your required package isn\u2019t listed, contact us. We may install it centrally or assist with installing it in your home directory.</p> </li> <li> <p>Estimate Resource Requirements</p> <p>Knowing how much memory or how many processes your job needs helps ensure successful execution. Try running a small version of your job first, then scale up. You can also use our development queue for testing.</p> </li> </ol> <p></p>"},{"location":"resources/compute_resources/","title":"Compute Resources","text":""},{"location":"resources/compute_resources/#general-description","title":"General Description","text":"<p>The Argon High Performance Computing (HPC) system at the University of Iowa was deployed in February 2017. It features a diverse set of compute node configurations, offering flexibility for a wide range of computational workloads.</p>"},{"location":"resources/compute_resources/#compute-node-configurations","title":"Compute Node Configurations","text":"<ul> <li>40-core: 96GB, 192GB  </li> <li>64-core: 192GB, 384GB, 768GB  </li> <li>80-core: 96GB, 192GB, 384GB, 768GB, 1.5TB  </li> <li>112-core: 256GB, 512GB, 1TB, 1.5TB  </li> <li>128-core: 256GB, 512GB, 1TB, 1.5TB  </li> </ul>"},{"location":"resources/compute_resources/#gpu-accelerators","title":"GPU Accelerators","text":"<p>Argon includes a wide variety of GPU-equipped machines to support accelerated computing:</p> <ul> <li>21 \u00d7 Nvidia P100  </li> <li>2 \u00d7 Nvidia K80  </li> <li>2 \u00d7 Nvidia P40  </li> <li>17 \u00d7 Nvidia 1080Ti  </li> <li>19 \u00d7 Nvidia Titan V  </li> <li>14 \u00d7 Nvidia V100  </li> <li>38 \u00d7 Nvidia 2080Ti  </li> <li>1 \u00d7 Nvidia RTX8000  </li> <li>7 \u00d7 Nvidia A100  </li> <li>5 \u00d7 machines with 4 \u00d7 A40 each  </li> <li>2 \u00d7 machines with 4 \u00d7 L40S each  </li> <li>1 \u00d7 machine with 4 \u00d7 L4  </li> </ul>"},{"location":"resources/compute_resources/#data-center-locations","title":"Data Center Locations","text":"<p>The Argon cluster is distributed across two data centers:</p> <ul> <li>ITF \u2013 Information Technology Facility </li> <li>LC \u2013 Lindquist Center</li> </ul> <p>Most nodes in the LC data center are connected via OmniPath high-speed interconnect fabric. Nodes in the ITF data center utilize Mellanox InfiniBand EDR fabric, which is split into two separate, non-interconnected fabrics\u2014referred to as islands.</p>"},{"location":"resources/compute_resources/#heterogeneity","title":"Heterogeneity","text":"<p>Unlike previous HPC systems at the University of Iowa, which were largely homogeneous,  Argon is a heterogeneous cluster with a wide mix of compute node types. This includes variability in both GPU accelerators and CPU architectures.</p>"},{"location":"resources/compute_resources/#cpu-architecture-and-avx-capabilities","title":"CPU Architecture and AVX Capabilities","text":"<p>Argon nodes feature processors with varying Advanced Vector Extensions (AVX) capabilities, which significantly impact performance and compatibility.</p> Architecture AVX Level Floating Point Ops/Cycle Notes Haswell / Broadwell AVX2 16 Skylake Silver AVX512 16 1 AVX unit per core Skylake Gold AVX512 32 2 AVX units per core Cascadelake Gold AVX512 32 Sapphire Rapids Gold AVX512 \u2014 <p>Code must be compiled with appropriate optimization flags to utilize AVX instructions.</p> <ul> <li>AVX512-optimized code will not run on Haswell/Broadwell systems (AVX2 only).  </li> <li>Backward compatibility is maintained: AVX2-optimized code will run on Skylake and newer architectures.</li> </ul>"},{"location":"running_jobs/batch_jobs/basic/","title":"Intro to Batch","text":""},{"location":"running_jobs/batch_jobs/basic/#introduction-to-batch-jobs","title":"Introduction to Batch Jobs","text":""},{"location":"running_jobs/overview/","title":"Overview","text":""},{"location":"software/containers/containers_on_hpc/","title":"Containers on HPC","text":""},{"location":"software/containers/containers_on_hpc/#containers-on-hpc","title":"Containers on HPC","text":""},{"location":"software/modules/","title":"Software Modules","text":"<p>High-Performance Computing (HPC) environments support a wide range of software applications, libraries, and compilers. Efficiently managing these resources can be challenging due to differing versions, configurations, and dependencies, which may lead to conflicts if not properly handled. </p> <p>To mitigate this, HPC systems utilize a module system. Software packages are installed in non-standard locations to avoid clashes with system-wide paths. Instead of altering global settings, users dynamically configure their environments using modules. With simple commands, they can load, unload, and switch between different software versions, ensuring a clean, consistent, and personalized computing environment.</p> <p>Software Stack</p> <p>Software packages in HPC environments are organized into sets known as <code>stacks</code>. Each stack contains a collection of software built with a consistent set of dependencies, ensuring compatibility within the stack. This approach allows multiple versions of the same software to coexist, each within its own well-defined environment. While switching between versions of a specific package can be more complex under this scheme, the recommended solution is to load the appropriate stack in a separate SSH session. This ensures a clean and conflict-free environment tailored to the specific version requirements.</p> <pre><code>dooyoon@argon-login-5 ~&gt; module spider stack\n\n-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n  stack:\n-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n     Versions:\n        stack/legacy\n        stack/2019.1\n        stack/2020.1\n        stack/2020.2-base_arch\n        stack/2020.2\n        stack/2021.1-base_arch\n        stack/2021.1\n        stack/2022.1-base_arch\n        stack/2022.1\n        stack/2022.2-base_arch\n        stack/2022.2\n</code></pre>"},{"location":"software/modules/#module-commands","title":"Module Commands","text":"Command Description <pre><code>module list</code></pre> Display the software you have loaded in your environment. <pre><code>module avail</code></pre> Display all installed modules under current stack matching the <code>&lt;module_name&gt;</code>. <pre><code>module spider &lt;module_name&gt; </code></pre> Display all installed modules available matching the <code>&lt;module_name&gt;</code>. <pre><code>module show &lt;module_name&gt; </code></pre> Displays system variables that are set/modified when loading module <code>&lt;module_name&gt;</code>. This can be helpful for locating the executables that are provided by the module. <pre><code>module load &lt;module_name&gt;</code></pre> Load a software module in your environment <pre><code>module unload &lt;module_name&gt;</code></pre> Unload a specific software package from your environment <pre><code>module reset</code></pre> Configure back to default set <pre><code>module purge</code></pre> Unload all software modules from your environment <pre><code>module save &lt;module_list_name&gt; </code></pre> Save the list of current modules to the name <code>module_list_name</code> <pre><code>module restore &lt;module_list_name&gt;</code></pre> Restore the list of modules from <code>module_list_name</code> <pre><code>module help</code></pre> Display a help menu for the module command"},{"location":"software/modules/#examples","title":"Examples","text":"List current modules<pre><code>dooyoon@argon-login-5 ~&gt; module list\n\nCurrently Loaded Modules:\n  1) stack/2021.1              4) expat/2.2.10_gcc-9.3.0    7) libxml2/2.9.10_gcc-9.3.0  10) libffi/3.3_gcc-9.3.0      13) readline/8.1_gcc-9.3.0            16) xz/5.2.5_gcc-9.3.0\n  2) bzip2/1.0.8_gcc-9.3.0     5) gdbm/1.19_gcc-9.3.0       8) tar/1.34_gcc-9.3.0        11) ncurses/6.2_gcc-9.3.0     14) sqlite/3.35.3_gcc-9.3.0           17) zlib/1.2.11_gcc-9.3.0\n  3) libbsd/0.10.0_gcc-9.3.0   6) libiconv/1.16_gcc-9.3.0   9) gettext/0.21_gcc-9.3.0    12) openssl/1.1.1k_gcc-9.3.0  15) util-linux-uuid/2.36.2_gcc-9.3.0  18) python/3.8.8_gcc-9.3.0\n</code></pre> Find the desired Python version<pre><code>dooyoon@argon-login-5 ~&gt; module spider python\n\n------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n  python:\n------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n     Versions:\n        python/2.7.13_parallel_studio-2017.1\n        python/2.7.13\n        ...\n        python/3.10.8_gcc-9.5.0-dev\n        python/3.10.8_gcc-9.5.0\n        python/3.10.8_intel-2021.7.1-dev\n        python/3.10.8_intel-2021.7.1\n        ...\n\n\n\ndooyoon@argon-login-5 ~&gt; module spider python/3.10.8_gcc-9.5.0\n\n-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n  python: python/3.10.8_gcc-9.5.0\n-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n\n    You will need to load all module(s) on any one of the lines below before the \"python/3.10.8_gcc-9.5.0\" module is available to load.\n\n      stack/2022.2\n      stack/2022.2-base_arch\n\n    Help:\n      The Python programming language.\n</code></pre> <p>Tip</p> <p>To load <code>Python 3.10.8</code>, you need to load <code>stack/2022.2</code>. </p> Load the Python version<pre><code>dooyoon@argon-login-5 ~&gt; module load stack/2022.2\n\nThe following have been reloaded with a version change:\n  1) stack/2021.1 =&gt; stack/2022.2\n\n\ndooyoon@argon-login-5 ~&gt; module load python/3.10.8_gcc-9.5.0\n\n\ndooyoon@argon-login-5 ~&gt; module list\n\nCurrently Loaded Modules:\n  1) stack/2022.2              5) expat/2.4.8_gcc-9.5.0      9) libiconv/1.16_gcc-9.5.0   13) pigz/2.7_gcc-9.5.0        17) libffi/3.4.2_gcc-9.5.0      21) util-linux-uuid/2.38.1_gcc-9.5.0\n  2) bzip2/1.0.8_gcc-9.5.0     6) ncurses/6.3_gcc-9.5.0     10) xz/5.2.7_gcc-9.5.0        14) zstd/1.5.2_gcc-9.5.0      18) libxcrypt/4.4.31_gcc-9.5.0  22) python/3.10.8_gcc-9.5.0\n  3) libmd/1.0.4_gcc-9.5.0     7) readline/8.1.2_gcc-9.5.0  11) zlib/1.2.13_gcc-9.5.0     15) tar/1.34_gcc-9.5.0        19) openssl/1.1.1s_gcc-9.5.0\n  4) libbsd/0.11.5_gcc-9.5.0   8) gdbm/1.23_gcc-9.5.0       12) libxml2/2.10.3_gcc-9.5.0  16) gettext/0.21.1_gcc-9.5.0  20) sqlite/3.39.4_gcc-9.5.0\n</code></pre> <p>Python and R packages</p> <p>Python and R packages have a name convention starting with \"py-\" and \"r-\", respectively. For example, the module for the <code>numpy</code> package is named as <code>py-numpy</code>:</p> <pre><code>dooyoon@argon-login-5 ~&gt; module avail py-numpy\n\n------------------------------------------------------------------------------------- /opt/ssoft/modules/2021.1/packages --------------------------------------------------------------------------------------\npy-numpy/1.19.5_gcc-9.3.0    py-numpydoc/1.1.0_gcc-9.3.0\n</code></pre> <p>To check all available packages, you will need to add patterns and Regular Expression (regex) option (<code>-r</code>) to the module search command:</p> <pre><code>dooyoon@argon-login-5 ~&gt; module -r avail ^py\n\n------------------------------------------------------------------------------------- /opt/ssoft/modules/2021.1/packages --------------------------------------------------------------------------------------\n   py-absl-py/0.10.0_gcc-9.3.0                     py-hypothesis/5.3.0_gcc-9.3.0                 py-pexpect/4.7.0_gcc-9.3.0                          py-simplejson/3.16.0_gcc-9.3.0\n   py-agate-dbf/0.2.1_gcc-9.3.0                    py-idna/2.8_gcc-9.3.0                         py-pickleshare/0.7.5_gcc-9.3.0                      py-sip/4.19.21_gcc-9.3.0-qt5\n   py-agate-excel/0.2.3_gcc-9.3.0                  py-imageio-ffmpeg/0.4.3_gcc-9.3.0             py-pillow/7.2.0_gcc-9.3.0                           py-sip/4.19.21_gcc-9.3.0                         (D)\n   py-agate-sql/0.5.4_gcc-9.3.0                    py-imageio/2.9.0_gcc-9.3.0                    py-pip/20.2_gcc-9.3.0                               py-six/1.15.0_gcc-9.3.0\n...\n</code></pre>"},{"location":"software/modules/#using-environment-modules-with-sge-jobs-and-qlogin","title":"Using Environment Modules with SGE Jobs and <code>qlogin</code>","text":""},{"location":"software/modules/#qlogin-sessions","title":"<code>qlogin</code> Sessions","text":"<p>For interactive sessions launched with <code>qlogin</code>, a fresh environment is created. This means that any environment modules loaded prior to launching <code>qlogin</code> will not be available in the session.</p> <p>For more details, refer to the Qlogin for Interactive Sessions.</p>"},{"location":"software/modules/#standard-qsub-jobs","title":"Standard <code>qsub</code> Jobs","text":"<p>For standard batch jobs submitted via <code>qsub</code>, the entire environment from the submit host is passed to the job by default, due to the <code>-V</code> flag being set in the default SGE request. This includes:</p> <ul> <li>The environment set up by loaded modules.</li> <li>The list of loaded modules themselves.</li> </ul> <p> However, it is recommended to explicitly include <code>module load</code> statements in your job script rather than relying on the inherited environment. This ensures:</p> <ul> <li>Greater reproducibility.</li> <li>Clear documentation of dependencies.</li> </ul> <p>To avoid conflicts or unintended behavior, add the lines below to your job script:</p> <pre><code>module purge\nmodule load stack/&lt;desired stack&gt;\nmodule load &lt;package&gt;\n</code></pre>"},{"location":"software/modules/#high-throughput-high-volume-computing-htchvc-jobs","title":"High Throughput / High Volume Computing (HTC/HVC) Jobs","text":"<p> For HTC or HVC workloads involving thousands of jobs, it is not advisable to load modules within each job script. Doing so can:</p> <ul> <li>Overload the module system.</li> <li>Lead to job failures due to rapid, repeated module loads.</li> </ul> <p>Therefore, it is recommended to </p> <ul> <li>Load all necessary modules before job submission.</li> <li>Ensure the submission environment is correctly configured.</li> <li>Avoid loading modules or module sets in your <code>~/.bashrc</code> file.</li> <li>Disable any default module sets if configured.</li> <li>You may include comments in your job scripts to document which modules are expected, but do not perform actual module loads within the script.</li> </ul>"},{"location":"software/overview/","title":"Overview","text":""},{"location":"software/overview/#software-installation-and-review","title":"Software Installation and Review","text":"<p>Software packages installed centrally on the Argon HPC system must comply with the University of Iowa's software licensing policies. Verifying compliance is a required part of the installation process and may take anywhere from a few days to several weeks, depending on the complexity of the software license agreement.</p> <p>In some cases, additional information may be needed from the requester to complete the review. Generally, the HPC team initiates the review process, but collaboration with the requester may be necessary. If the software was purchased by a college or department, the collegiate or departmental IT staff are typically best positioned to lead the review.</p>"},{"location":"software/overview/#license-scenarios-and-review-requirements","title":"License Scenarios and Review Requirements","text":"Open Source Software with a Standard License <p> If the software is open source and licensed under one of the pre-approved open source licenses, it is already compliant and can be deployed without further review. </p> <p> Refer to: Open Source Licensing \u2013 Technology Review | ITS </p> <p> Once the distribution logistics are finalized, deployment can proceed.</p> Freely Available or Open Source Software with a Non-Standard License <p> If the software uses a license not on the approved list\u2014even if it is free or open source\u2014it must go through the technology review process.   </p> <ul> <li>Review details: Technology Reviews Information | ITS</li> </ul> <p>   This review ensures there are no problematic clauses in the license. In some cases, access restrictions may be required. For example, software that requires registration for download or use may need controls to ensure compliance with academic or educational licensing terms.   </p> Purchased Software with a License Agreement <p>   Software purchased with a formal license agreement typically requires the most extensive review. The signed agreement must be submitted for evaluation.   </p> <p>   Such software almost always requires a defined access control scheme before deployment is approved by the University of Iowa General Counsel.   </p> Previously Reviewed Software <p> Some software may already be on the University's Reviewed and Approved List: </p> <p>   Check here: List of Reviewed Agreements | ITS</p> <p> Even if a software title is listed, we must verify that its license permits installation on an HPC cluster. Many licenses are limited to individual or departmental use and may exclude cluster environments. </p> <p> In such cases, deployment may still be possible, but only after defining and approving an appropriate access control strategy.</p>"},{"location":"software/overview/#post-review","title":"Post-Review","text":"<p>Once the software has been reviewed and authorized, possibly with access controls, it can be deployed centrally on the Argon HPC system. While deployment logistics can often begin in parallel with the review process, please plan accordingly to allow time for all steps to be completed.</p>"},{"location":"software/popular_software/R/rbatch/","title":"Running R Programs in Job Scripts on Argon","text":"<p>To run an <code>R</code> program inside a job script on Argon, you must be able to execute the <code>R</code> script from the command line\u2014without using the interactive <code>R</code> prompt. <code>R</code> provides the <code>Rscript</code> command for this purpose, which is available in all R modules on Argon.</p>"},{"location":"software/popular_software/R/rbatch/#basic-usage","title":"Basic Usage","text":"<p>If you normally process a dataset on your Windows or Unix workstation like this:</p> <pre><code>$ cd path/to/dataSet123\n$ Rscript my/scripts/program.R inputDataSet123.txt &gt; output123.txt\n</code></pre> <p>You can do the same on Argon by composing a job script that loads the appropriate R modules:</p> <pre><code>module reset\nmodule load r\ncd path/to/dataSet123\nRscript my/scripts/program.R inputDataSet123.txt &gt; output123.txt\n</code></pre> <p>Using SGE and Scratch Filesystems for Better Performance</p> <p>To improve performance by following HTC Best Practice, you can use SGE to temporarily store output on Argon's /localscratch filesystem:</p> <pre><code>#$ -j y\n#$ -o /localscratch\n\nmodule reset\nmodule load r\ncd path/to/dataSet123\nRscript my/scripts/program.R inputDataSet123.txt\nmv $SGE_STDOUT_PATH .\n</code></pre> <p>Avoiding R CMD BATCH</p> <p>Some tutorials suggest using the older <code>R CMD BATCH program.R</code> convention. However, this approach has several drawbacks, especially on HPC systems:</p> <ul> <li>It simulates an interactive session and prints output inline with the script, making it harder to read or parse.</li> <li>It does not print to standard output (stdout), so you can't use SGE or redirection (&gt;).</li> <li>It always creates a file named <code>program.Rout</code> in the current directory, which may not align with your input/output locations and can cause performance issues.</li> </ul> <p>Recommendation: Use <code>Rscript</code> instead of <code>R CMD BATCH</code></p>"},{"location":"software/popular_software/R/rbatch/#running-mpi-jobs-with-r-using-r-snow","title":"Running MPI Jobs with R (Using R-snow)","text":"<p>Running MPI jobs with R with the <code>R-snow</code> package requires special handling.</p>"},{"location":"software/popular_software/R/rbatch/#single-node-execution","title":"Single-Node Execution","text":"<p>If all MPI processes run on a single host, you can start R normally and spawn MPI ranks within the script.</p>"},{"location":"software/popular_software/R/rbatch/#multi-node-execution","title":"Multi-Node Execution","text":"<p>For multi-node jobs, processes must be spawned using <code>mpirun</code>. This also works for single-node jobs. Since <code>mpirun</code> starts <code>R</code>, you need a wrapper to distinguish between primary and secondary processes. This wrapper is called <code>RMPISNOW</code>.</p>"},{"location":"software/popular_software/R/rbatch/#launching-the-job","title":"Launching the Job","text":"<pre><code>mpirun -np &lt;num_processes&gt; RMPISNOW CMD BATCH --slave sample_script.R\n</code></pre> <ul> <li>The <code>SGE</code> slot request must be one greater than the number of workers.</li> <li>If no additional slots are requested for memory, <code>mpirun</code> will use the <code>SGE</code> environment settings.</li> </ul> <p>You can also simplify the command: <pre><code>mpirun RMPISNOW CMD BATCH --slave sample_script.R\n</code></pre></p>"},{"location":"software/popular_software/R/rbatch/#inside-the-r-script","title":"Inside the R Script","text":"<p>To reference the snow cluster created by mpirun, use:</p> <pre><code>mpi.universe.size() - 1     # Number of workers\n\ncl &lt;- getMPIcluster()       # Create cluster object\nstopCluster(cl)             # Stop the cluster\nmpi.quit()                  # Exit the R session\n</code></pre> <p><code>mpi.universe.size()</code> is the total number of MPI processes, so the number of workers is set to be one less.</p> <p>Warning</p> <p>Note: Rscript cannot be used with the <code>RMPISNOW</code> wrapper, as it directly calls R. Alternatively, you can run the command as:</p> <pre><code>mpirun RMPISNOW --slave &lt; sample_script.R\n</code></pre>"},{"location":"software/popular_software/R/rlibrary/","title":"Adding R programs to a personal library","text":"<p>There are two main approaches to managing R packages in a personal library:</p> <ol> <li> <p>Global Personal R Library    Create a personal library in your home directory for a specific version of R. This allows packages to be available whenever you use that version.</p> </li> <li> <p>Project-Specific Environments with Packrat    Use Packrat to create isolated, portable environments for each R project. This ensures reproducibility and avoids package conflicts across projects.</p> </li> </ol>"},{"location":"software/popular_software/R/rlibrary/#option-1-global-personal-r-library","title":"Option 1: Global Personal R Library","text":"<p>Installing R packages locally is straightforward:</p> <ol> <li> <p>Load the R module</p> <pre><code>dooyoon@argon-itf-login-3 ~&gt; module load r\n\ndooyoon@argon-itf-login-3 ~&gt; module list\n\nCurrently Loaded Modules:\n  1) stack/2021.1                      14) gdbm/1.19_gcc-9.3.0             27) xcb-proto/1.14.1_gcc-9.3.0     40) graphite2/1.3.13_gcc-9.3.0      53) openjdk/11.0.8_10_gcc-9.3.0\n  2) bzip2/1.0.8_gcc-9.3.0             15) perl/5.32.1_gcc-9.3.0           28) xextproto/7.3.0_gcc-9.3.0      41) harfbuzz/2.6.8_gcc-9.3.0        54) gobject-introspection/1.56.1_gcc-9.3.0\n  3) font-util/1.3.2_gcc-9.3.0         16) libbsd/0.10.0_gcc-9.3.0         29) xproto/7.0.31_gcc-9.3.0        42) icu4c/67.1_gcc-9.3.0            55) libxft/2.3.2_gcc-9.3.0\n  4) libiconv/1.16_gcc-9.3.0           17) expat/2.2.10_gcc-9.3.0          30) xtrans/1.3.5_gcc-9.3.0         43) intel-mkl/2020.4.304_gcc-9.3.0  56) pango/1.41.0_gcc-9.3.0\n  5) libxml2/2.9.10_gcc-9.3.0          18) openssl/1.1.1k_gcc-9.3.0        31) libxcb/1.14_gcc-9.3.0          44) libjpeg-turbo/2.0.6_gcc-9.3.0   57) pcre2/10.35_gcc-9.3.0\n  6) util-linux-uuid/2.36.2_gcc-9.3.0  19) sqlite/3.35.3_gcc-9.3.0         32) libxext/1.3.3_gcc-9.3.0        45) libpng/1.6.37_gcc-9.3.0         58) readline/8.1_gcc-9.3.0\n  7) fontconfig/2.13.1_gcc-9.3.0       20) python/3.8.8_gcc-9.3.0          33) renderproto/0.11.1_gcc-9.3.0   46) libtiff/4.1.0_gcc-9.3.0         59) scrnsaverproto/1.2.2_gcc-9.3.0\n  8) freetype/2.10.4_gcc-9.3.0         21) glib/2.66.8_gcc-9.3.0           34) libxrender/0.9.10_gcc-9.3.0    47) libx11/1.7.0_gcc-9.3.0          60) libxscrnsaver/1.2.2_gcc-9.3.0\n  9) tar/1.34_gcc-9.3.0                22) inputproto/2.3.2_gcc-9.3.0      35) pixman/0.40.0_gcc-9.3.0        48) libice/1.0.9_gcc-9.3.0          61) tcl/8.6.11_gcc-9.3.0\n 10) gettext/0.21_gcc-9.3.0            23) kbproto/1.0.7_gcc-9.3.0         36) cairo/1.16.0_gcc-9.3.0         49) libsm/1.2.3_gcc-9.3.0           62) tk/8.6.10_gcc-9.3.0\n 11) libffi/3.3_gcc-9.3.0              24) libpthread-stubs/0.4_gcc-9.3.0  37) libunistring/0.9.10_gcc-9.3.0  50) libxmu/1.1.2_gcc-9.3.0          63) xz/5.2.5_gcc-9.3.0\n 12) pcre/8.44_gcc-9.3.0               25) libxau/1.0.8_gcc-9.3.0          38) libidn2/2.3.0_gcc-9.3.0        51) libxt/1.1.5_gcc-9.3.0           64) zlib/1.2.11_gcc-9.3.0\n 13) berkeley-db/18.1.40_gcc-9.3.0     26) libxdmcp/1.1.2_gcc-9.3.0        39) curl/7.76.0_gcc-9.3.0          52) ncurses/6.2_gcc-9.3.0           65) r/4.0.5_gcc-9.3.0\n</code></pre> </li> <li> <p>Launch <code>R</code></p> <pre><code>dooyoon@argon-itf-login-3 ~&gt; R\n\nR version 4.0.5 (2021-03-31) -- \"Shake and Throw\"\nCopyright (C) 2021 The R Foundation for Statistical Computing\nPlatform: x86_64-pc-linux-gnu (64-bit)\n\nR is free software and comes with ABSOLUTELY NO WARRANTY.\nYou are welcome to redistribute it under certain conditions.\nType 'license()' or 'licence()' for distribution details.\n\n  Natural language support but running in an English locale\n\nR is a collaborative project with many contributors.\nType 'contributors()' for more information and\n'citation()' on how to cite R or R packages in publications.\n\nType 'demo()' for some demos, 'help()' for on-line help, or\n'help.start()' for an HTML browser interface to help.\nType 'q()' to quit R.\n\n[Previously saved workspace restored]\n\n&gt; \n</code></pre> </li> <li> <p>Install a package</p> <p>Replace \"package_name\" with the desired package name: </p> <pre><code>&gt; install.packages(\"package_name\", repos = \"http://cran.r-project.org\")\n</code></pre> </li> </ol> <p>Not Writable warning</p> <p>You may see a warning like:</p> <pre><code>Warning in install.packages(\"package_name\", repos = \"http://cran.r-project.org\") : 'lib = \"/opt/R/3.0.2/lib64/R/library\"' \nis not writable Would you like to use a personal library instead? (y/n)\n</code></pre> <p>Select y to use a personal library. Select y again when prompted to create the directory.</p> <p>The package will then be installed into your newly created personal library.</p>"},{"location":"software/popular_software/R/rlibrary/#option-2-packrat-project-directory","title":"Option 2: Packrat Project Directory","text":"<p>Packrat is an R package that enables isolated environments for each project. On the Argon HPC cluster:</p> <ul> <li>Packrat is available starting with R version 3.3.2.</li> <li> <p>For newer versions (e.g., modules named r-#.#.# from 3.6.2 onward or stack modules like YYYY.# from 2019.1), the r-packrat module must be loaded manually.</p> </li> <li> <p>Create a project directory</p> <pre><code>dooyoon@argon-itf-login-3 ~&gt; mkdir ~/myproject\ndooyoon@argon-itf-login-3 ~&gt; cd ~/myproject\n</code></pre> </li> <li> <p>Start <code>R</code> (follow the step 1 and 2 in the Option 1) and initialize Packrat</p> <p><pre><code>packrat::init()\n</code></pre> From this point on, any packages you install will be stored in the project-specific library.</p> </li> </ul>"},{"location":"software/popular_software/R/rlibrary/#resuming-packrat-project","title":"Resuming Packrat Project","text":"<ul> <li><code>cd</code> into the project directory.</li> <li>Start <code>R</code> \u2014 Packrat will load automatically.</li> </ul>"},{"location":"software/popular_software/R/rlibrary/#using-packrat-from-the-shell","title":"Using Packrat from the Shell","text":"<pre><code>dooyoon@argon-itf-login-3 ~&gt; mkdir ~/someproject\ndooyoon@argon-itf-login-3 ~&gt; cd ~/someproject\ndooyoon@argon-itf-login-3 ~&gt; Rscript -e 'packrat::init(enter=FALSE)'\ndooyoon@argon-itf-login-3 ~&gt; Rscript -e 'install.packages(c(\"brms\", \"rstanarm\"))'\n</code></pre>"},{"location":"software/popular_software/jupyter/","title":"Running a Jupyter Notebook on Argon","text":"<p>Although Argon is not designed to host a full JupyterHub installation, you can still run a Jupyter Notebook on Argon and connect to it using a web browser on your local machine. This requires setting up a network path, typically using SSH tunneling, between the system running the notebook (Argon) and your local computer.</p> <p>To use a browser on your local machine, one end of the SSH tunnel must be on your computer.</p> <p>The instructions below are specific to the Argon HPC system, including how to select a Python environment and run Jupyter.</p> <p>Always run Jupyter Notebook on compute nodes using the SGE scheduler. Running it on login nodes can negatively impact system performance for others.</p> <ol> <li> <p>Create a Script to Launch Jupyter Notebook</p> <pre><code>$ mkdir -p $HOME/bin\n$ echo -e '#!/bin/bash\\njupyter notebook --ip=$(hostname -f) --no-browser --port=8080' &gt; $HOME/bin/notebook.sh\n</code></pre> <ul> <li>This creates a directory for your personal scripts and adds a script to launch Jupyter Notebook.</li> <li>The port number <code>8080</code> can be replaced with any available four-digit port.</li> </ul> Contents of notebook.sh<pre><code>#!/bin/bash\njupyter notebook --ip=$(hostname -f) --no-browser --port=8080\n</code></pre> </li> <li> <p>Convert the script to be executable</p> <pre><code>$ chmod +x $HOME/bin/notebook.sh\n</code></pre> </li> <li> <p>Load required modules </p> <pre><code>$ module load python\n$ module load py-jupyter\n</code></pre> <p>important</p> <p>The default Python version is 2.7, so you should load the Python module to use a later version of Python. Check the available Python versions by: <pre><code>$ module spider python\n</code></pre></p> <p>You will need to load the required Python packages to use in the notebook. For example,  <pre><code>$ module load py-numpy\n$ module load py-matplotlib\n</code></pre></p> <p>For more information, refer to the Module page.</p> <p>Alternatively, you can activate a Python virtual environment or Conda virtual environment to build the list of packages you need. See Python page for the detailed information. </p> </li> <li> <p>Launch Jupyter Notebook on a Compute Node</p> <p>Use the SGE scheduler to request compute resources: <pre><code>$ qrsh -q UI -N Jupyter -pe smp 2 -cwd $HOME/bin/notebook.sh\n</code></pre></p> <p>In this example, it requests <code>UI</code> queue with 2 slots (<code>-pe smp 2</code>) and the name of the job is Jupyter. The <code>-cwd</code> flag indicates that the Jupyter Notebook will access the current directory. You can modify the queue, number of slots, and the Job name.</p> <p>If successful, you\u2019ll see output like:</p> </li> </ol>"},{"location":"software/popular_software/python/","title":"Establishing Python Environment","text":""},{"location":"software/popular_software/python/#available-python-environments-on-hpc-systems","title":"Available Python Environments on HPC Systems","text":"<p>The HPC systems provide a variety of Python installations for users to choose from. To view the available Python modules, run:</p> <p><pre><code>dooyoon@argon-login-6 ~&gt; module spider python\n\n----------------------------------------------------------------------------\n  python:\n----------------------------------------------------------------------------\n     Versions:\n        python/2.7.13_parallel_studio-2017.1\n        python/2.7.13\n        ...\n        python/3.10.8_gcc-9.5.0-dev\n        python/3.10.8_gcc-9.5.0\n        python/3.10.8_intel-2021.7.1-dev\n        python/3.10.8_intel-2021.7.1\n</code></pre> Python packages in the module environment have a naming convention with the prepix <code>py-xxx</code>. For more details, Refer to the Software Modules.</p>"},{"location":"software/popular_software/python/#python-virtual-environment","title":"Python Virtual Environment","text":"<p>Python virtual environments is a self-contained Python setup with its own:</p> <ul> <li>Python interpreter</li> <li><code>pip</code> installer</li> <li>Package directory</li> </ul> <p>This allows you to modify or test environments independently, isolate codebases with conflicting dependencies, and manage multiple projects more effectively.</p> <p>Warning</p> <p>The Python version will be fixed to the one that is used to create the virtual environment. Therefore, you should carefully choose the Python version in the stack environment and load it before establishing the environment. </p> <p>Follow steps below to create a virtual environment and install packages:</p> <ol> <li> <p>Check Available Python Modules     <pre><code>$ module spider python\n\n----------------------------------------------------------------------------\n  python:\n----------------------------------------------------------------------------\n     Versions:\n        python/2.7.13_parallel_studio-2017.1\n        python/2.7.13\n        ...\n        python/3.10.8_gcc-9.5.0-dev\n        python/3.10.8_gcc-9.5.0\n        python/3.10.8_intel-2021.7.1-dev\n        python/3.10.8_intel-2021.7.1\n</code></pre></p> </li> <li> <p>Load the Desired Python Module     <pre><code>$ module spider python/3.10.8_gcc-9.5.0\n\n-----------------------------------------------------------------------------------------------------------------------------------------\n  python: python/3.10.8_gcc-9.5.0\n-----------------------------------------------------------------------------------------------------------------------------------------\n    You will need to load all module(s) on any one of the lines below before the \"python/3.10.8_gcc-9.5.0\" module is available to load.\n      stack/2022.2\n      stack/2022.2-base_arch\n      ...\n$ module load stack/2022.2\n$ module load python/3.10.8_gcc-9.5.0\n</code></pre></p> </li> <li> <p>Create a Directory for Virtual Environments if you don't have it yet     <pre><code>$ mkdir $HOME/virtenvs\n</code></pre></p> <p>Tip</p> <p>You'll probably make a few environments for testing and unrelated tasks, and it's common convention to create a directory to keep them organized:</p> </li> <li> <p>Create a Virtual Environment     <pre><code>$ python -m venv $HOME/virtenvs/someProject\n</code></pre>     This creates a directory named someProject containing the environment configuration.</p> <p>If you want the environment to include packages from the loaded module (e.g., MKL-linked NumPy/SciPy), use: <pre><code>$ python -m venv --system-site-packages $HOME/virtenvs/someProject\n</code></pre></p> </li> <li> <p>Activate the virtual environment     <pre><code>$ source $HOME/virtenvs/someProject/bin/activate\n</code></pre>     Your shell prompt will change to indicate the active environment:     <pre><code>(someProject) $\n</code></pre></p> </li> <li> <p>Upgrade Core Tools</p> <p>Before installing packages, upgrade pip, setuptools, and wheel:</p> <pre><code>(someProject) $ pip install -U pip setuptools wheel\n</code></pre> </li> <li> <p>Install Packages</p> <pre><code>(someProject) $ pip install -U package1 package2 package3\n</code></pre> <p>Tip</p> <p>The <code>-U</code> option upgrades all specified packages to the newest available version. Omit this option if you don't want to upgrade packages. For more options with <code>pip install</code>, see the pip documentation.</p> </li> <li> <p>Deactivate the Environment</p> <p>When you're done, you can get out of the virtual environment by the following command: <pre><code>(someProject) $ deactivate\n</code></pre> This restores your shell to its previous state and removes the (someProject) prompt.</p> </li> <li> <p>Reuse the Environment</p> <p>To reuse the environment later (e.g., in a job script or interactive session), simply activate it again:</p> <pre><code>$ source $HOME/virtenvs/someProject/bin/activate\n</code></pre> <p>You can continue installing, removing, or running packages as needed.</p> <p>Tip</p> <p>To use the virtual environment in a cluster job script, simply activate it there the same way.</p> </li> </ol>"},{"location":"software/popular_software/python/#using-conda-on-hpc-systems","title":"Using Conda on HPC Systems","text":"<p>Conda is a popular tool for installing Python software along with its dependencies and managing virtual environments, especially on personal laptops or workstations.</p> <p>You can install Conda via:</p> <ul> <li>Miniconda: A minimal installer that sets up the base Conda system, allowing you to install only the packages you need.</li> <li>Anaconda: A larger installer that includes the base Conda system plus a wide selection of commonly used scientific packages.</li> </ul> <p>For more details, refer to the Conda User Guide</p> <p>Conda provides functionality similar to what\u2019s already available in the HPC environment, such as:</p> <ul> <li>Python installations</li> <li>Package management via <code>pip</code></li> <li>Virtual environment support via <code>virtualenv</code></li> </ul> <p>While it\u2019s possible to install Conda in your home directory or a shared group drive, it operates independently of the HPC module system. If you need specific Python packages not currently available in the HPC environment, consider requesting them from HPC staff before installing Conda yourself.</p> <p>Important</p> <p>A default Anaconda installation includes software that can interfere with graphical logins (e.g., FastX) by overriding system paths. See this workaround.</p>"},{"location":"software/popular_software/python/#installing-anaconda-on-argon","title":"Installing Anaconda on Argon","text":"<ol> <li> <p>Download the installer from the Anaconda archive</p> <pre><code>$ curl -RLO https://repo.anaconda.com/archive/Anaconda3-2024.10-1-Linux-x86_64.sh\n</code></pre> </li> <li> <p>Execute the installer</p> <pre><code>$ bash Anaconda3-2024.10-1-Linux-x86_64.sh\n</code></pre> <p>During installation, you\u2019ll be asked whether to modify your shell configuration (e.g., .bashrc) to initialize Conda automatically at login. This may slightly slow down login times.</p> <p>If you choose to initialize Conda, the following block will be added to your <code>.bashrc</code>:</p> <pre><code># &gt;&gt;&gt; conda initialize &gt;&gt;&gt;\n# !! Contents within this block are managed by 'conda init' !!\n__conda_setup=\"$('$HOME/anaconda3/bin/conda' 'shell.bash' 'hook' 2&gt; /dev/null)\"\nif [ $? -eq 0 ]; then\n    eval \"$__conda_setup\"\nelse\n    if [ -f \"$HOME/anaconda3/etc/profile.d/conda.sh\" ]; then\n        . \"$HOME/anaconda3/etc/profile.d/conda.sh\"\n    else\n        export PATH=\"$HOME/anaconda3/bin:$PATH\"\n    fi\nfi\nunset __conda_setup\n# &lt;&lt;&lt; conda initialize &lt;&lt;&lt;\n</code></pre> <p>You can comment out these lines later if you prefer not to auto-initialize Conda at login.</p> If you skipped shell modification during installation but want to set the automatic Conda initialization afterward: <pre><code>$ eval \"$($HOME/anaconda3/bin/conda shell.bash hook)\"\n$ conda init\n</code></pre> <p>This will add the configuration lines above to your .bashrc. </p> <p>Once the Conda is initiated, your prompt will show the base environment:</p> <pre><code>(base) $\n</code></pre> </li> <li> <p>Create a New Environment</p> <pre><code>(base) $ conda create -n someProject\n</code></pre> <p>Tip</p> <p>Unlike the Python virtual environment, you can install different Python versions within the Conda virtual environment. You can still create a Conda environment with the specific Python version as well.</p> <pre><code>(base) $ conda create -n someProject python=&lt;Python_version&gt;\n</code></pre> </li> <li> <p>Activate the Environment</p> <p><pre><code>(base) $ source activate someProject\n</code></pre> Your prompt will change to:</p> <pre><code>(someProject) $\n</code></pre> </li> <li> <p>Install Packages</p> <p>You can now search for and install packages. For example,</p> <p><pre><code>(someProject) $ conda install numpy scipy matplotlib\n</code></pre> For more commands, see the Conda Cheatsheet.</p> </li> <li> <p>Deactivate the Environment</p> <p>Once your work is done, you can get out of the Conda environment by</p> <p><pre><code>(someProject) $ source deactivate\n</code></pre> This will return your shell to its previous state.</p> </li> </ol> <p>Additional Tip</p> <ul> <li>List the packages already installed in one of your Conda environments like so:     <pre><code>$ conda list -n someProject\n</code></pre></li> <li> <p>Remove a particular packag     <pre><code>$ conda remove -n someProject opencv\n</code></pre></p> </li> <li> <p>Remove an entire Conda environment like so:     <pre><code>$ conda remove -n someProject --all\n</code></pre></p> </li> <li> <p>List all remaining environments like so:     <pre><code>$ conda info --envs\n</code></pre></p> </li> </ul>"},{"location":"software/user_installations/","title":"User Installations","text":""},{"location":"software/user_installations/#package-managers","title":"Package managers","text":""},{"location":"support/consultation/","title":"Consulting Services","text":""},{"location":"support/nsf_access/","title":"NSF ACCESS CI","text":""},{"location":"workshops/Basic_Linux/commands/","title":"Getting started with Linux Command Line using Argon","text":"<p>In this page, the essential Linux commands are listed. You can exercise all commands below on the Argon cluster.</p>"},{"location":"workshops/Basic_Linux/commands/#first-helpers","title":"First helpers","text":"<p>man [option] [section number] [command name]</p> <p>display a comprehensive guide of commands. If no section number, it will print out the entire manual of the requested command.</p> <p>history [option]</p> <p>check previous run utilities</p> <pre><code>dooyoon@argon-itf-login-3 ~&gt; history\n1  cd\n2  ls\n</code></pre>"},{"location":"workshops/Basic_Linux/commands/#navigation","title":"Navigation","text":"<p>pwd [option]</p> <p>print current working directory's path</p> <ul> <li>-L (--logical)</li> <li>-P (--physical)</li> </ul> <p>ls [option] [/directory/folder/path]</p> <p>list files and directories in your system</p> <p>Options</p> <ul> <li>-a: show hidden content</li> <li>-R: list items inside subfolders</li> <li>-h: print file sizes in human-readable format</li> <li>-F: type of objects  /: directory, @: link, *: executable</li> <li>-l: display detailed information </li> </ul> <pre><code> dooyoon@argon-itf-login-4 ~&gt; ls -altrh\n total 4.5M\n -rw-r--r--  1 dooyoon 5.4K Dec  7  2023 .vimrc\n drwxr-xr-x  2 dooyoon    5 Dec  7  2023 .vim-file\n lrwxrwxrwx  1 dooyoon   26 Feb 19  2024 nfsscratch -&gt; /nfsscratch/Users/dooyoon/\n drwx------  3 dooyoon    3 Feb 28  2024 .dbus\n -rw-------  1 dooyoon   16 Feb 28  2024 .esd_auth\n drwxr-xr-x  2 dooyoon    2 Feb 28  2024 Desktop\n drwxr-xr-x  2 dooyoon    2 Feb 28  2024 Downloads\n drwxr-xr-x  2 dooyoon    2 Feb 28  2024 Templates\n</code></pre> <p>cd [/directory/folder/path]</p> <p>move to the destination folder</p> <ul> <li>Absolute path: start w/ the root directory and provide the full path to the file or directory</li> <li>Relative path: a path to a file or directory that is relative to the current directory  </li> </ul>"},{"location":"workshops/Basic_Linux/commands/#filedirectory-manipulation","title":"File/Directory Manipulation","text":"<p>mkdir [directory name]</p> <p>create one or multiple directories</p> <p> cp [option] [source object] [target path or file name]</p> <p>copy files or directories to another file names or target ath</p> <p>Options </p> <ul> <li>-R: all sub-directory</li> <li>-f: force to copy</li> <li>-v: verbose</li> </ul> <p>mv [source object] [target path or file name]</p> <p>move files or directories to a new location or rename them</p> <p>rm [option] [file names or directory names]</p> <p>remove files or directories</p> <p>Options </p> <ul> <li>-i: prompt a confirmation before deletion</li> <li>-f: allow file removal without confirmation</li> <li>-r: delete files and directories recursively</li> </ul> <p>Warning</p> <p>In most cases, deleted files and directories cannot be recovered. </p> <p>touch [option] [file name]</p> <p>create a new empty file in a specific directory</p> <p>cat [file name]</p> <p>print the content of a text file</p> <p>Info</p> <p>You can also use <code>cat</code> with the operator to combine multiple files into a new file. </p> <pre><code>dooyoon@argon-itf-login-4 ~&gt; cat file1.txt file2.txt &gt; target_file.txt\n</code></pre> <p>head [option] [file name]</p> <p>print the first few entries of a file </p> <p>Options</p> <ul> <li>-n: number of lines</li> </ul> <p>tail [option] [file name]</p> <p>print the last few entries of a file</p> <p>Options </p> <ul> <li>-n: number of lines</li> <li>-f: output appended the data (i.e., display the lines in real time)</li> </ul> <p>grep [option] keyword [file name]</p> <p>search specific lines from a file using keyword  -&gt; Useful for filtering large data like logs</p> <p>ln [option] [source] [destination]</p> <p>create links between files or directories</p> <ul> <li>hard link:<ul> <li>only files on a same partition</li> <li>link to inode</li> </ul> </li> <li>symbolic link:<ul> <li>option: <code>-s</code></li> <li>point to files or directories</li> <li>considered as \"shortcuts\"</li> </ul> </li> </ul> <pre><code>dooyoon@argon-itf-login-4 links_hard_symbolic&gt; ls -il *\n  285698 -rw-r--r-- 2 dooyoon 4 Sep  3 15:33 source1\n  285698 -rw-r--r-- 2 dooyoon 4 Sep  3 15:33 source1-hard\n  285699 -rw-r--r-- 1 dooyoon 4 Sep  3 15:22 source2\n  285701 lrwxrwxrwx 1 dooyoon 7 Sep  3 15:30 source2-soft -&gt; source2\n</code></pre> <p>which [command]</p> <p>search for executable First commands in the PATH environment</p> <p>whereis [option] [command]</p> <p>display the path of the binary source, and manual page files in the PATH or MANPATH environment</p> <p>locate [option] [command]</p> <p>search all files that include pattern in the pre-existed database</p> <p>find [dir] [option] [expression]</p> <p>search files and directories in any designated directory</p> <p>chmod [option] [permission] [file or directory]</p> <p>change permission of files or directories</p> <ul> <li>u: user / g: group / o: other / a: all</li> <li>r: read / w: write / x: execute</li> </ul> <pre><code>dooyoon@argon-itf-login-4 Executable&gt; ls -l\n  -rwxr--r-- 1 dooyoon 38 Sep  5 14:08 hello.sh\n\ndooyoon@argon-itf-login-4 Executable&gt; chmod ugo+x hello.sh\ndooyoon@argon-itf-login-4 Executable&gt; ls -l\n  -rwxr-xr-x 1 dooyoon 38 Sep  5 14:08 hello.sh\n</code></pre> <ul> <li>Octal Number: r=4 / w=2 / x=1</li> </ul> <pre><code>dooyoon@argon-itf-login-4 Executable&gt; chmod 755 hello.sh\ndooyoon@argon-itf-login-4 Executable&gt; ls -l\n  -rwxr-xr-x 1 dooyoon 38 Sep  5 14:08 hello.sh\n</code></pre> <p>df [option] [file system]</p> <p>check your system's disk usage</p> <p>Options </p> <ul> <li>-h: print file sizes in human-readable format</li> </ul> <pre><code>dooyoon@argon-itf-login-3 ~&gt; df -h $HOME\n  Filesystem                          Size  Used Avail Use% Mounted on\n  172.29.4.38:/dpool01/Homes/dooyoon  1.0T   20G 1005G   2% /old_Users/dooyoon\n</code></pre> <p>du [option] [directory]</p> <p>check the size of a directory and its content</p> <p>Options </p> <ul> <li>-h: print file sizes in human-readable format</li> <li>-d, --max-depth=N: print the total for a directory only if it is N or fewer levels below.  </li> </ul>"},{"location":"workshops/Basic_Linux/commands/#archive-unpack-targets","title":"Archive &amp; Unpack targets","text":"<p>tar [option] [archive file] [target objects]</p> <p>bundle multiple files or directories into an archive</p> <p>Options </p> <ul> <li>c or x: create or extract</li> <li>v     : verbose</li> <li>f     : specify the archive file</li> <li>z or j: compression (file extension -&gt; .tar.gz or .tar.bz2)          without compression, the extension will be .tar</li> </ul> <p>zip [option] [archive file] [target objects]</p> <p>bundle and compress multiple files or directories using zip</p> <p>unzip [option] [archive file]</p> <p>extract the zip archived file</p>"},{"location":"workshops/Basic_Linux/commands/#file-transfer","title":"File Transfer","text":"<p>wget [option] [URL]</p> <p>download files from the internet via HTTP, HTTPS, or FTP protocols</p> <p>curl [option] [URL]</p> <p>transfer data from or to a server by specifying its URL</p> <p>Options</p> <ul> <li>-O/-o: download files from the specific link</li> </ul> <p>scp [option] [source] [address]:[destination folder]</p> <p>securely copy files and directories between systems over a network</p> <p>rsync [option] [source] [address]:[destination folder]</p> <p>syncs files or directories between two destinations to ensure they have the same content</p> <p>Options </p> <ul> <li>-r: recurse into sub-directories</li> <li>-a: archive mode, keeps all file permissions, symbolic links,file ownership, etc</li> <li>-u: skip files that are newer on the receiver</li> </ul>"},{"location":"workshops/Basic_Linux/editors/","title":"Text Editors on Linux","text":"NanoVim/Vi <p>Nano is a straightforward and user-friendly text editor, making it a great choice for beginners.</p> <ul> <li> <p>Opening a file</p> <pre><code>nano filename.txt\n</code></pre> </li> <li> <p>Basic Commands</p> Command Description Type Edit text directly <code>Ctrl + O</code> Save changes <code>Ctrl + X</code> Exit the editor (prompt to save if needed) <code>Ctrl + K</code> Cut the current line <code>Ctrl + U</code> Paste the cut line <code>Ctrl + W</code> Search for text Arrow keys Navigate through the text </li> </ul> <p>Vim (Vi IMproved) is a powerful text editor that is widely used in the Linux environment. It operates in different modes, primarily Normal, Insert, and Visual modes.</p> <ul> <li> <p>Opening a File</p> <pre><code>vi filename.txt\n</code></pre> </li> <li> <p>Basic Commands in Normal Mode</p> Command Description i Switch to Insert mode a Switch to Insert mode (append) v Switch to Visual mode :w Save changes :wq Save and exit :q! Exit without saving h, j, k, l Navigate left, down, up, and right, respectively dd Delete the current line u Undo the last action </li> </ul> <p>You can exit from Insert Mode by hitting ESC key. It will change the status to Normal Mode</p>"},{"location":"workshops/Intro_HPC/","title":"Introduction of HPC using Argon","text":""},{"location":"workshops/Intro_HPC/#accessing-argon","title":"Accessing Argon","text":"<p>details</p> <ul> <li> <p>On campus or off campus with VPN</p> <pre><code>&gt; ssh HawkID@argon.hpc.uiowa.edu\n</code></pre> </li> <li> <p>Off campus without VPN</p> <pre><code>&gt; ssh -p 40 HawkID@argon.hpc.uiowa.edu\n</code></pre> </li> </ul> <p>The activation of VPN is recommended for security when you access outside campus.</p>"},{"location":"workshops/Intro_HPC/#evironment-modules-on-argon","title":"Evironment modules on Argon","text":"<p>details</p> <p>module list</p> <p>list currently loaded modules</p> <pre><code>dooyoon@argon-itf-login-4 ~&gt; module list\n\n  Currently Loaded Modules:\n    1) stack/2021.1\n</code></pre> <p>module avail [package]</p> <p>search information of the package under the current stack</p> <p>module spider [package]</p> <p>search detailed information of the package in all stacks</p> <p>module load [package]</p> <p>load the module </p> <p>module unload [package]</p> <p>unload the module</p> <p>module reset</p> <p>set the environment to the default configuration</p> <p>module purge</p> <p>remove all modules </p>"},{"location":"workshops/Intro_HPC/#sge-jobs","title":"SGE Jobs","text":"<p>details: basic submission details: advanced submission</p> <p>qsub [job script]</p> <p>submit a job with batch script</p> <p>qstat -u [HawkID]</p> <p>check the state of the submitted job</p> <p>Status:</p> <ul> <li>r:   running</li> <li>qw:  waiting in the queue</li> </ul> <p>qdel [job ID number]</p> <p>cancel the submitted job either waiting in the queue or running</p> <p>qlogin [option]</p> <p>interactive SGE session for a requested time period</p> <p>Options - SGE derivatives: </p> <ul> <li>-q [queue name]</li> <li>-pe smp [number of slots]    </li> <li>...</li> </ul>"},{"location":"workshops/Intro_HPC/#sample-batch-script-for-a-job-submission","title":"Sample batch script for a job submission","text":"<pre><code>   #!/bin/bash\n\n   #####Set Scheduler Configuration Directives#####\n   # Set the name of the job.\n   # This will be the first part of the job's .o (output) and .e (error) file names.\n   #$ -N sleeper\n\n   # By default, the job's working directory is the $HOME directory.\n   # Here, set it the same as the current working directory when the job was submitted.\n   # The job's .o (output) and .e (error) files will be written here.\n   #$ -cwd\n\n   # Send e-mail at beginning/end/suspension of job:\n   #$ -m bes\n\n   # E-mail address to send to:\n   #$ -M [your Iowa email address]\n   #####End Set Scheduler Configuration Directives#####\n\n   #####Resource Selection Directives#####\n   # Provide a comma-separated list of queues the scheduler can consider for this job:\n   #$ -q [queue name]\n\n   # Specify the number of slots the job will use:\n   #$ -pe smp [number of slots]\n   #####End Resource Selection Directives#####\n\n   #####Load Modules####\n   #module reset\n   #module load ...\n   #####Load Modules####\n\n   #####Begin Compute Work#####\n   # During the job, print information to stdout, which will be written into the job's output file:\n   /bin/echo \"Running on compute node: $(hostname).\"\n   /bin/echo \"In directory: $(pwd)\"\n   /bin/echo \"Starting on: $(date)\"\n\n   # Invoke the programs we want to run, and provide any necessary input parameters.\n   # First, we start the \"sleep\" command so that it waits 60 seconds, then exits:\n   sleep 60\n\n   # Print the end date of the job before exiting:\n   echo \"Job ended: $(date)\"\n   #####End Compute Work#####\n</code></pre>"},{"location":"workshops/overview/","title":"ITS Workshops and Training Materials","text":"<p>The Information Technology Services (ITS) regularly hosts workshops focused on Basic Linux and High-Performance Computing (HPC). These sessions are designed to help researchers, faculty, staff, and students learn how to effectively use the university\u2019s supercomputing cluster, Argon, for computational research.</p> <p>This subsection provides supplementary materials for those workshops, including tutorials, and example scripts. If you're interested in attending a future workshop, please check the ITS Research Services Workshops page on details.</p> <p>For technical documentation and detailed information about the Argon cluster, visit the Argon wiki page If you do not yet have access, please visit the Argon HPC service page. Accounts are available at no cost to UI faculty, staff, and students who are conducting research. Once your account is approved, you\u2019ll be able to log in and begin using the cluster for your computational tasks.</p>"}]}